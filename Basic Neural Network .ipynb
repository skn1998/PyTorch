{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Basic Neural Network .ipynb","provenance":[],"authorship_tag":"ABX9TyORoA0NiV8Jv1qmx3gQ1NJv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"tD8htBP8UV5x","colab_type":"text"},"source":["**Imports**"]},{"cell_type":"code","metadata":{"id":"i4rBv881keK_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600151693982,"user_tz":-330,"elapsed":1338,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}}},"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q-B_Gt1yUsOC","colab_type":"text"},"source":["**Devise Congfiguration**"]},{"cell_type":"code","metadata":{"id":"kCkxP_aPUbVD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600151693985,"user_tz":-330,"elapsed":1329,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}}},"source":["device = 'cpu'"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u6GgtizqVBjz","colab_type":"text"},"source":["**Hyperparameters**"]},{"cell_type":"code","metadata":{"id":"xX5O9kuHVECH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600151693987,"user_tz":-330,"elapsed":1322,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}}},"source":["input_size = 784 # 28x28 images\n","hidden_size = 100\n","num_classes = 10\n","num_epochs = 10\n","batch_size = 100\n","learning_rate = 0.001"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s_XjL4xZVW3x","colab_type":"text"},"source":["**MNIST Dataset**"]},{"cell_type":"code","metadata":{"id":"6cXUiGh1VZ65","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600151693989,"user_tz":-330,"elapsed":1316,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}}},"source":["train_data = torchvision.datasets.MNIST(root='/content/sample_data', train=True, transform=transforms.ToTensor(), download=True)\n","test_data = torchvision.datasets.MNIST(root='/content/sample_data', train=False, transform=transforms.ToTensor())\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DfkAbi1iXTBA","colab_type":"text"},"source":["**Neural Network**"]},{"cell_type":"code","metadata":{"id":"7CPCmcEaW3Br","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600151693990,"user_tz":-330,"elapsed":1309,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}}},"source":["class NeuralNetwork(nn.Module):\n","  def __init__(self, input_size, hidden_size, num_classes):\n","    super(NeuralNetwork, self).__init__()\n","    self.l1 = nn.Linear(input_size, hidden_size)\n","    self.relu = nn.ReLU()\n","    self.l2 = nn.Linear(hidden_size, num_classes)\n","    ## No softmax at the end as it will get applied by CrossEntropyLoss \n","\n","  def forward(self, x):\n","    out = self.l1(x)\n","    out = self.relu(out)\n","    out = self.l2(out)\n","    return out\n","\n","model = NeuralNetwork(input_size, hidden_size, num_classes)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1XYgqzsnZcxT","colab_type":"text"},"source":["**Loss and Optimizer**"]},{"cell_type":"code","metadata":{"id":"mwAX-0pdZSUK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600151693992,"user_tz":-330,"elapsed":1302,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}}},"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3kAl_19nZw8G","colab_type":"text"},"source":["**Training Loops**"]},{"cell_type":"code","metadata":{"id":"-7vWetk9Zv9L","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600151769148,"user_tz":-330,"elapsed":76448,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}},"outputId":"87a8f39b-3bf5-4a66-cfa0-838d1152078d"},"source":["n_total_steps = len(train_loader)\n","for epoch in range(num_epochs):\n","  for i, (images, labels) in enumerate(train_loader):\n","    # resizing the tensors\n","    images = images.reshape(-1, 28*28)\n","    labels = labels\n","\n","    # forward pass\n","    outputs = model(images)\n","    loss = criterion(outputs, labels)\n","\n","    # backward pass\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (i+1)%100==0:\n","      print(f'epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["epoch 1 / 10, step 100/600, loss = 0.4150\n","epoch 1 / 10, step 200/600, loss = 0.4520\n","epoch 1 / 10, step 300/600, loss = 0.3367\n","epoch 1 / 10, step 400/600, loss = 0.2709\n","epoch 1 / 10, step 500/600, loss = 0.1071\n","epoch 1 / 10, step 600/600, loss = 0.2802\n","epoch 2 / 10, step 100/600, loss = 0.2573\n","epoch 2 / 10, step 200/600, loss = 0.1607\n","epoch 2 / 10, step 300/600, loss = 0.2039\n","epoch 2 / 10, step 400/600, loss = 0.2068\n","epoch 2 / 10, step 500/600, loss = 0.0910\n","epoch 2 / 10, step 600/600, loss = 0.1781\n","epoch 3 / 10, step 100/600, loss = 0.0794\n","epoch 3 / 10, step 200/600, loss = 0.1888\n","epoch 3 / 10, step 300/600, loss = 0.2031\n","epoch 3 / 10, step 400/600, loss = 0.0552\n","epoch 3 / 10, step 500/600, loss = 0.1471\n","epoch 3 / 10, step 600/600, loss = 0.1104\n","epoch 4 / 10, step 100/600, loss = 0.1009\n","epoch 4 / 10, step 200/600, loss = 0.0541\n","epoch 4 / 10, step 300/600, loss = 0.1276\n","epoch 4 / 10, step 400/600, loss = 0.1731\n","epoch 4 / 10, step 500/600, loss = 0.0733\n","epoch 4 / 10, step 600/600, loss = 0.0493\n","epoch 5 / 10, step 100/600, loss = 0.0612\n","epoch 5 / 10, step 200/600, loss = 0.0749\n","epoch 5 / 10, step 300/600, loss = 0.1307\n","epoch 5 / 10, step 400/600, loss = 0.1446\n","epoch 5 / 10, step 500/600, loss = 0.0279\n","epoch 5 / 10, step 600/600, loss = 0.0955\n","epoch 6 / 10, step 100/600, loss = 0.0346\n","epoch 6 / 10, step 200/600, loss = 0.1412\n","epoch 6 / 10, step 300/600, loss = 0.1597\n","epoch 6 / 10, step 400/600, loss = 0.1159\n","epoch 6 / 10, step 500/600, loss = 0.0529\n","epoch 6 / 10, step 600/600, loss = 0.0480\n","epoch 7 / 10, step 100/600, loss = 0.0719\n","epoch 7 / 10, step 200/600, loss = 0.1070\n","epoch 7 / 10, step 300/600, loss = 0.0757\n","epoch 7 / 10, step 400/600, loss = 0.0568\n","epoch 7 / 10, step 500/600, loss = 0.0612\n","epoch 7 / 10, step 600/600, loss = 0.0259\n","epoch 8 / 10, step 100/600, loss = 0.0295\n","epoch 8 / 10, step 200/600, loss = 0.0464\n","epoch 8 / 10, step 300/600, loss = 0.0917\n","epoch 8 / 10, step 400/600, loss = 0.0372\n","epoch 8 / 10, step 500/600, loss = 0.0177\n","epoch 8 / 10, step 600/600, loss = 0.0306\n","epoch 9 / 10, step 100/600, loss = 0.0402\n","epoch 9 / 10, step 200/600, loss = 0.0632\n","epoch 9 / 10, step 300/600, loss = 0.0443\n","epoch 9 / 10, step 400/600, loss = 0.0220\n","epoch 9 / 10, step 500/600, loss = 0.0571\n","epoch 9 / 10, step 600/600, loss = 0.0569\n","epoch 10 / 10, step 100/600, loss = 0.0084\n","epoch 10 / 10, step 200/600, loss = 0.0475\n","epoch 10 / 10, step 300/600, loss = 0.0216\n","epoch 10 / 10, step 400/600, loss = 0.0074\n","epoch 10 / 10, step 500/600, loss = 0.0399\n","epoch 10 / 10, step 600/600, loss = 0.0136\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZZbTYQAibdCo","colab_type":"text"},"source":["**Testing and Evaluation**"]},{"cell_type":"code","metadata":{"id":"YrkSDl89bfE2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1600151964665,"user_tz":-330,"elapsed":2046,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}},"outputId":"99499cd3-19da-4564-9688-d35c46eccf03"},"source":["with torch.no_grad(): # to stop tracking we will use torch.no_grad()\n","  n_correct = 0\n","  n_samples = 0\n","  for images, labels in test_loader:\n","    images = images.reshape(-1, 28*28)\n","    outputs = model(images)\n","\n","    _, predictions = torch.max(outputs, 1)\n","    n_samples += labels.shape[0]\n","    n_correct += (predictions==labels).sum().item()\n","\n","acc = 100*(n_correct/n_samples)\n","print(\"Accuracy on test data is :\", acc)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Accuracy on test data is : 97.68\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b_5o6R1IfUOC","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}