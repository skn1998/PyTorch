{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Batch Training(Dataset, DataLoader), Softmax and CrossEntropy in PyTorch.ipynb","provenance":[],"authorship_tag":"ABX9TyOH7wK8hxY1rbRh8HPvxtkq"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"7Bgh_hN86d36","colab_type":"text"},"source":["**Imports**"]},{"cell_type":"code","metadata":{"id":"0wse2rtq5-GC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600101201322,"user_tz":-330,"elapsed":6103,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}}},"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import math"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tidzH9WU653d","colab_type":"text"},"source":["**Dataset**"]},{"cell_type":"code","metadata":{"id":"TiqBI8xO64ZF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1600101231572,"user_tz":-330,"elapsed":1774,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}},"outputId":"239bfef5-2876-49bf-ee8b-871722217b0b"},"source":["class WineDataset(Dataset):\n","  def __init__(self):\n","    # data loading\n","    xy = np.loadtxt(\"/content/wine.data\", delimiter=\",\", dtype=np.float32)\n","    self.x = torch.from_numpy(xy[: , 1:])\n","    self.y = torch.from_numpy(xy[:, [0]])\n","    self.n_samples = xy.shape[0]\n","\n","  def __getitem__(self, index):\n","    return (self.x[index], self.y[index])\n","\n","  def __len__(self):\n","    return self.n_samples\n","\n","dataset = WineDataset()\n","first_data = dataset[0]\n","features, label = first_data\n","print(features, label)    "],"execution_count":3,"outputs":[{"output_type":"stream","text":["tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n","        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n","        1.0650e+03]) tensor([1.])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AxSY4tQ2mh0N","colab_type":"text"},"source":["**Using DataLoader**"]},{"cell_type":"code","metadata":{"id":"JLK-5S8pk2OO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600101235466,"user_tz":-330,"elapsed":1524,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}}},"source":["dataloader = DataLoader(dataset=dataset, batch_size=32, shuffle=True) # it provides an iteratable over the data set and is used in batch training"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ykA3C-B3nE3p","colab_type":"text"},"source":["**Training loop**"]},{"cell_type":"code","metadata":{"id":"F_ROBxQ3m9FD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1600101236572,"user_tz":-330,"elapsed":2213,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}},"outputId":"8d5b5dcc-b795-4670-ac5a-4caaf070e1dc"},"source":["num_epochs = 20\n","total_samples = len(dataset)\n","n_iterations = math.ceil(total_samples/32)\n","print(total_samples, n_iterations)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["178 6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AfSeFFYLnrXn","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600101236573,"user_tz":-330,"elapsed":2056,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}}},"source":["for epoch in range(num_epochs):\n","  for i, (inputs, labels) in enumerate(dataloader):\n","    # write normal code here\n","    pass\n"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k5hGSPqw4knG","colab_type":"text"},"source":["*Softmax in PyTorch*"]},{"cell_type":"code","metadata":{"id":"tgg4slru4gqo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1600101236574,"user_tz":-330,"elapsed":1714,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}},"outputId":"486dc5c6-7a06-436f-ee7e-656997a3190b"},"source":["x = torch.tensor([2.0, 5.0, 1.0])\n","y = torch.softmax(x, dim=0)\n","print(y)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["tensor([0.0466, 0.9362, 0.0171])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"npi9wk5e6B2F","colab_type":"text"},"source":["*Cross Entropy in PyTorch*"]},{"cell_type":"code","metadata":{"id":"KwOZDe0I4w5t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600101238171,"user_tz":-330,"elapsed":2782,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}},"outputId":"5bdf031c-8a89-4afc-9dd7-1f366bc5ed91"},"source":["def crossentropy(actual, predicted):\n","  loss = -np.sum(actual * np.log(predicted))\n","  return loss \n","\n","Y = np.array([1, 0, 0]) # one hot encoded vector\n","Y_pred_good = np.array([0.7, 0.2, 0.1])\n","Y_pred_bad = np.array([0.1, 0.3, 0.6])\n","\n","l1 = crossentropy(Y, Y_pred_good)\n","l2 = crossentropy(Y, Y_pred_bad)\n","print(\"Loss on good prediction :\", l1)\n","print(\"Loss on bad prediction: \", l2)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Loss on good prediction : 0.35667494393873245\n","Loss on bad prediction:  2.3025850929940455\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b3mJLWsh7F5a","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600101238174,"user_tz":-330,"elapsed":2275,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}},"outputId":"05756a02-2dab-4437-ca25-f3f86e04f350"},"source":["# doing it in PyTorch\n","\n","loss = nn.CrossEntropyLoss()\n","Y = torch.tensor([0])\n","Y_pred_good = torch.tensor([[2.0, 0.1, 1.1]])   # note here we pass the raw values because softmax is automatically applied by CrossEntropyLoss(VVI) where as in case of Binary Classification we need to implemenmt sigmoid because nn.BCELoss() dosent implement it\n","Y_pred_bad = torch.tensor([[0.1, 0.9, 3.1]])\n","l1 = loss(Y_pred_good, Y)\n","l2 = loss(Y_pred_bad, Y)\n","print(\"Loss on good prediction :\", l1.item())\n","print(\"Loss on bad prediction: \", l2.item())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Loss on good prediction : 0.4422072768211365\n","Loss on bad prediction:  3.148928642272949\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nUXctV8O8lCv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1600101238181,"user_tz":-330,"elapsed":1796,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}},"outputId":"eae61e68-5044-4259-89c0-e63756221a31"},"source":["# for getting the prediction\n","_, predictions1 = torch.max(Y_pred_good, 1)\n","_, predictions2= torch.max(Y_pred_bad, 1)\n","print(\"Prediction of class in good prediction: \", predictions1.item())\n","print(\"Prediction of class in bad prediction: \", predictions2.item())\n","\n","# NOTE: We have computed loss for one sample but we can do so for multiple samples also"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Prediction of class in good prediction:  0\n","Prediction of class in bad prediction:  2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lfYLVd6a-Eo0","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600101201339,"user_tz":-330,"elapsed":6009,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}}},"source":[""],"execution_count":null,"outputs":[]}]}