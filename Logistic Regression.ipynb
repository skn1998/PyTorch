{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Logistic Regression.ipynb","provenance":[],"authorship_tag":"ABX9TyO4Ty4Jj+vjg7HwdG/fgvzq"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"V-_SyQgTFRbL","colab_type":"text"},"source":["**Imports**"]},{"cell_type":"code","metadata":{"id":"-NKZm5ccRTTJ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600064612729,"user_tz":-330,"elapsed":1731,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}}},"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","from sklearn import datasets\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split "],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MtSe_z02F6V4","colab_type":"text"},"source":["**Dataset Preparation**"]},{"cell_type":"code","metadata":{"id":"dQhr-ZVBFpYN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600064612731,"user_tz":-330,"elapsed":1706,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}},"outputId":"adec1471-b803-468b-e90f-bafac0e2065a"},"source":["# loading the brest cancer dataset\n","bc = datasets.load_breast_cancer()\n","X, y = bc.data, bc.target\n","n_samples, n_features = X.shape\n","print(n_samples, n_features)\n","\n","# train test split \n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n","\n","# applying scaling on train and test data\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# converting everythin from numpy to tensor\n","X_train = torch.from_numpy(X_train.astype(np.float32))\n","X_test = torch.from_numpy(X_test.astype(np.float32))\n","y_train = torch.from_numpy(y_train.astype(np.float32))\n","y_test = torch.from_numpy(y_test.astype(np.float32))\n","\n","print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n","print(y_train)\n","\n","# reshaping \n","y_train = y_train.view(y_train.shape[0], 1)\n","y_test = y_test.view(y_test.shape[0], 1)\n","print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n","print(y_train)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["569 30\n","torch.Size([455, 30]) torch.Size([455]) torch.Size([114, 30]) torch.Size([114])\n","tensor([0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,\n","        1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.,\n","        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0.,\n","        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n","        0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n","        0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n","        0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n","        1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n","        0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,\n","        0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.,\n","        0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.,\n","        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n","        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n","        1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0.,\n","        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.,\n","        0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\n","        1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n","        0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n","        1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,\n","        0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0.,\n","        0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n","        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,\n","        1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.,\n","        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n","        0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n","        0., 1., 0., 1., 1.])\n","torch.Size([455, 30]) torch.Size([455, 1]) torch.Size([114, 30]) torch.Size([114, 1])\n","tensor([[0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [0.],\n","        [1.],\n","        [1.]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lNjJqX6YI37I","colab_type":"text"},"source":["**Model**"]},{"cell_type":"code","metadata":{"id":"uLWmsr_OGYOT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600064612733,"user_tz":-330,"elapsed":1684,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}}},"source":["class LogisticRegression(nn.Module):\n","  def __init__(self, num_inputs):\n","    super(LogisticRegression, self).__init__()\n","    self.linear = nn.Linear(num_inputs, 1)\n","\n","  def forward(self, x): \n","    y_pred = torch.sigmoid(self.linear(x))\n","    return(y_pred)\n","\n","model = LogisticRegression(n_features)   "],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KP8xxZjPKKhy","colab_type":"text"},"source":["**Loss and Optimizer**"]},{"cell_type":"code","metadata":{"id":"Mk6FP73tKDPT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600064612736,"user_tz":-330,"elapsed":1660,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}}},"source":["learning_rate = 0.01\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.SGD(params=model.parameters(), lr=learning_rate)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8dyT1qI9Kc4B","colab_type":"text"},"source":["**Training Loop**"]},{"cell_type":"code","metadata":{"id":"s9XTkcoiKg0B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":351},"executionInfo":{"status":"ok","timestamp":1600064612738,"user_tz":-330,"elapsed":1646,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}},"outputId":"18e79670-bf92-4224-bb8b-352e9099f704"},"source":["num_epochs = 1000\n","for epoch in range(num_epochs):\n","  # forward pass and loss\n","  y_pred = model(X_train)\n","  loss = criterion(y_pred, y_train)\n","\n","  # backward pass and gradient computation \n","  loss.backward()\n","\n","  # update of weights\n","  optimizer.step()\n","\n","  optimizer.zero_grad()  # making the gradients 0 \n","\n","  if (epoch+1)%50==0:\n","    print(f'epoch = {epoch+1}, loss = {loss.item()}')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["epoch = 50, loss = 0.3184701204299927\n","epoch = 100, loss = 0.24071693420410156\n","epoch = 150, loss = 0.20385263860225677\n","epoch = 200, loss = 0.18142607808113098\n","epoch = 250, loss = 0.1660081148147583\n","epoch = 300, loss = 0.15461508929729462\n","epoch = 350, loss = 0.14578238129615784\n","epoch = 400, loss = 0.1386934071779251\n","epoch = 450, loss = 0.1328517347574234\n","epoch = 500, loss = 0.12793640792369843\n","epoch = 550, loss = 0.12373003363609314\n","epoch = 600, loss = 0.12007958441972733\n","epoch = 650, loss = 0.11687420308589935\n","epoch = 700, loss = 0.11403131484985352\n","epoch = 750, loss = 0.1114882230758667\n","epoch = 800, loss = 0.10919621586799622\n","epoch = 850, loss = 0.10711692273616791\n","epoch = 900, loss = 0.10521969944238663\n","epoch = 950, loss = 0.10347964614629745\n","epoch = 1000, loss = 0.10187637805938721\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2HkbDr5KLY_3","colab_type":"text"},"source":["**Model Evaluation**"]},{"cell_type":"code","metadata":{"id":"nHE5ZVwULHf8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1600064612740,"user_tz":-330,"elapsed":1636,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}},"outputId":"caac48c2-34aa-49fb-bd45-2243eeb0af19"},"source":["with torch.no_grad():  # now we don't want to trach the history\n","  y_pred = model(X_test)\n","  y_pred_class = y_pred.round()\n","  acc = y_pred_class.eq(y_test).sum() / float(y_test.shape[0])\n","  print(\"Accuracy on the test set equals : \", acc.item())"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Accuracy on the test set equals :  0.9649122953414917\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"38gwAl3SMWGZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600064613157,"user_tz":-330,"elapsed":2050,"user":{"displayName":"SK Nishant","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgjHBBXkzROI66Y-9uUeHJQxrYz6uv5Mz_vwWQoYg=s64","userId":"16914142004871895535"}}},"source":[""],"execution_count":6,"outputs":[]}]}